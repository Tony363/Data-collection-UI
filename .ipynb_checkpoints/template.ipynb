{
 "cells": [
  {
   "source": [
    "pip install xgboost==0.80"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: xgboost==0.80 in c:\\users\\tony\\desktop\\github_01\\xgboost-with-raymond\\venv\\lib\\site-packages (0.80)\nRequirement already satisfied: numpy in c:\\users\\tony\\desktop\\github_01\\xgboost-with-raymond\\venv\\lib\\site-packages (from xgboost==0.80) (1.17.4)\nRequirement already satisfied: scipy in c:\\users\\tony\\desktop\\github_01\\xgboost-with-raymond\\venv\\lib\\site-packages (from xgboost==0.80) (1.3.2)\nNote: you may need to restart the kernel to use updated packages.\n"
    }
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "source": [
    "from random import seed\n",
    "from random import random\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 14
  },
  {
   "source": [
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "for _ in range(100):\n",
    "    row=[]\n",
    "    x1 = random()\n",
    "    x2 = random()\n",
    "    px1=str(round(x1,3))\n",
    "    px2=str(round(x2,3))\n",
    "    row.append(x1)\n",
    "    row.append(x2)\n",
    "    X.append(row)\n",
    "    #print(float(px1), float(px2))\n",
    "    if x1+x2>1:  \n",
    "        z=1\n",
    "        Y.append(z)    \n",
    "    else: \n",
    "        z=0\n",
    "        Y.append(z)\n",
    "\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.06002940186412309, 0.7567625478394715], [0.6035392730145307, 0.1594646326686049], [0.6906684262029652, 0.6175949760686991], [0.24790552250064612, 0.6214218513141703], [0.002947859875845338, 0.7061236991845306], [0.7467314824430854, 0.5695829192350634], [0.4419095603941672, 0.8636576935322364], [0.7036877866368401, 0.2832770828671284], [0.14030696338714677, 0.12369115195042713], [0.9886584553026077, 0.9246053307858536], [0.6232390004807089, 0.04517133341698942], [0.4895354931538678, 0.44940459000962374], [0.27509618770346733, 0.035706987575980786], [0.24823434700185942, 0.54566980220367], [0.6687702867711197, 0.09950357836479373], [0.5011515101814255, 0.8632300155752651], [0.2914137258574173, 0.7390023892075969], [0.923339895039244, 0.2808720248172838], [0.9807864869266066, 0.3391358884427006], [0.9033579954886715, 0.32268603095293147], [0.966577227871559, 0.8308462855326901], [0.025801412998223472, 0.6727108432055818], [0.7331046778127813, 0.07131033739305426], [0.06552062291061567, 0.5844227043920622], [0.5480686307917608, 0.06041582428963954], [0.9480297858179771, 0.7959515484890529], [0.8861269532673913, 0.19606634438462567], [0.7650492850938814, 0.30216629791059846], [0.9836179045423366, 0.6799748420833768], [0.20571400563992737, 0.09010175813258114], [0.13668225666597433, 0.9396870258298261], [0.33378312789861775, 0.3320840121130342], [0.5524244336246752, 0.6086063863466645], [0.2709509667799669, 0.6614886434645062], [0.018516527949013484, 0.2399737715210437], [0.9374386169401018, 0.7263678469977817], [0.895370059627917, 0.41795425518298357], [0.22829879255086183, 0.3266473691921017], [0.6324301322390126, 0.7564663473273879], [0.7159058493845137, 0.9457615671312202], [0.9253765991235662, 0.4162206825255169], [0.2823550736727508, 0.285335224202094], [0.6081754616061822, 0.06613509350296665], [0.5126907008739306, 0.7771399558175719], [0.8837691959252382, 0.5307237861112932], [0.7496304020759789, 0.9934716432109181], [0.1720799626711369, 0.1589309196316111], [0.7255375106659459, 0.22810640002020122], [0.7847620770551983, 0.7709939956555072], [0.043789321341158094, 0.8445875259583485], [0.7416881014197447, 0.3309646155361783], [0.23318026695008875, 0.36640642004187274], [0.8026412455631902, 0.1944023819446653], [0.4413918683634721, 0.09741196992331203], [0.4464748110091107, 0.41121847876797135], [0.7972231001288433, 0.0289265868856875], [0.051398731806873266, 0.18908053186221407], [0.9089920143673879, 0.14480818455814115], [0.38714447963492116, 0.3037813822373955], [0.06097006544363437, 0.8836326997105102], [0.3614472284750265, 0.6493449161640733], [0.9169221564509468, 0.7004518368229993], [0.3666876055615942, 0.9287310661066795], [0.5645486419101134, 0.7563961285256013], [0.24830859490478352, 0.9154431568077681], [0.7410769743492839, 0.5813601743817275], [0.7590223497138276, 0.5569395514106131], [0.015563382573406725, 0.3181643724585056], [0.27775586548407805, 0.11256510952952059], [0.30755679306075356, 0.39452249467643696], [0.09874675630930352, 0.7156721264329662], [0.32343672830851566, 0.5002188760720966], [0.03650479352889768, 0.7432398065867092], [0.011660433739217213, 0.21301465684962184], [0.5080595715684675, 0.36584922035796097], [0.2302976157372254, 0.9002152262134232], [0.09410053421794506, 0.9273972403305197], [0.24559560384028978, 0.4009613042749769], [0.2899139780769835, 0.7436342280207935], [0.8304820905288208, 0.8312785282030811], [0.204213908184108, 0.57310968572868], [0.5974187103415555, 0.15909474275890367], [0.6916512101581357, 0.95692586190682], [0.6247231745695454, 0.660864953057348], [0.6692113032211652, 0.7055325344405693], [0.6901441433150968, 0.3062658259887693], [0.5068749318866838, 0.2025970601226903], [0.6158931695165664, 0.2828506934638906], [0.440788881313962, 0.02414303726668532], [0.8028480637242164, 0.8478995082760736], [0.3931958273942109, 0.9112572417592727], [0.3398676994518175, 0.3395488958759454], [0.9001878830420372, 0.8233368081272124], [0.6464667030244384, 0.8790395821532968], [0.8970324595284629, 0.10522732802675483], [0.08562210035056539, 0.6015568948327306], [0.2712146815335418, 0.8148298689418904], [0.30005502933458483, 0.7218224496202251], [0.2056638490088485, 0.546517852453937], [0.313787096581126, 0.603789388725996]]\n[0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n"
    }
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X[0:70],label=Y[0:70])\n",
    "dtest = xgb.DMatrix(X[71:100],label=Y[71:100])\n",
    "\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[22:16:48] 120x4 matrix with 480 entries loaded from dtrain.svm\n[22:16:48] 30x4 matrix with 120 entries loaded from dtest.svm\n"
    }
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "source": [
    "param = {\n",
    "        'max_depth': 2, \n",
    "        'eta': 1, \n",
    "        'objective': 'binary:logistic'\n",
    "        }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "num_round = 10"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 17
  },
  {
   "source": [
    "# classifier = XGBClassifier()\n",
    "# classifier.fit(X_train, Y_train)\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 18
  },
  {
   "source": [
    "bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "preds = bst.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n[0]\teval-auc:0.914286\ttrain-auc:0.949755\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[1]\teval-auc:0.935714\ttrain-auc:0.989379\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[2]\teval-auc:0.966667\ttrain-auc:0.997549\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[3]\teval-auc:0.966667\ttrain-auc:1\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n[4]\teval-auc:0.97619\ttrain-auc:1\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[5]\teval-auc:0.961905\ttrain-auc:1\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[6]\teval-auc:0.97619\ttrain-auc:1\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[7]\teval-auc:0.97619\ttrain-auc:1\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n[8]\teval-auc:0.980952\ttrain-auc:1\n[22:16:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\n[9]\teval-auc:0.980952\ttrain-auc:1\n"
    }
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "source": [
    "bst.save_model('0001.model')\n",
    "bst.dump_model('dump.raw.txt')"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 20
  },
  {
   "source": [
    "# bst_svm = xgb.train(param, dtrain_svm, num_round)\n",
    "# preds_ = bst.predict(dtest_svm)\n",
    "# best_preds_svm = [np.argmax(line) for line in preds_]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 21
  },
  {
   "source": [
    "# bst_svm.save_model('0002.model')\n",
    "# bst_svm.dump_model('dump_svm.raw.txt','featmap.txt')"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 22
  },
  {
   "source": [
    "bst = xgb.Booster({'nthread': 4})  # init model\n",
    "# bst.load_model('model.bin')  # load data\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 23
  },
  {
   "source": [
    "print(\"Numpy array precision:{}\".format(precision_score(Y_test, best_preds )))\n",
    "    \n",
    "# print(\"Svm file precision:{}\".format(precision_score(Y_test, best_preds_svm)) )"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20, 29]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-87a651f7dc48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Numpy array precision:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_preds\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(\"Svm file precision:{}\".format(precision_score(Y_test, best_preds_svm)) )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tony\\Desktop\\github_01\\xgboost-with-raymond\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m   1567\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1569\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1570\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tony\\Desktop\\github_01\\xgboost-with-raymond\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1413\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1415\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tony\\Desktop\\github_01\\xgboost-with-raymond\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                          str(average_options))\n\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tony\\Desktop\\github_01\\xgboost-with-raymond\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tony\\Desktop\\github_01\\xgboost-with-raymond\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20, 29]"
     ]
    }
   ],
   "metadata": {},
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}